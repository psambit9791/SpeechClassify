{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5baef5a150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "torch.cuda.set_device(2)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data and generate spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = pd.read_hdf('song_df.h5', 'song_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/scratch/s1769454/anaconda3/envs/dissertation/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "plt.ioff()\n",
    "for i in range(len(song_df.index)):\n",
    "    a = song_df.iloc[i].Data\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(0.375*2,0.375*2), frameon=False, facecolor='black')\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_facecolor(\"black\")\n",
    "    #fig.add_axes(ax)\n",
    "    frequencies, times, spectrogram = signal.spectrogram(a, 16000)\n",
    "    plt.pcolormesh(np.log(spectrogram))\n",
    "    plt.axis('off')\n",
    "    #plt.show()\n",
    "    filename = song_df.iloc[i].Name + \".png\"\n",
    "    #fig.set_tight_layout(True)\n",
    "    extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "    #plt.savefig('/tmp/test.png', bbox_inches=extent)\n",
    "    fig.savefig(\"./spectrograms/\"+filename, bbox_inches=extent)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Log of Spectrogram caused an error because spectrogram values had 0 in sing034_3 due to the pause in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data</th>\n",
       "      <th>Freq</th>\n",
       "      <th>Type</th>\n",
       "      <th>MFCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>sing034_3</td>\n",
       "      <td>[-19464192, -16252928, -5177344, 14483456, 465...</td>\n",
       "      <td>16000</td>\n",
       "      <td>0</td>\n",
       "      <td>[[38.812406955625654, -6.280405806858493, -13....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name                                               Data   Freq  \\\n",
       "373  sing034_3  [-19464192, -16252928, -5177344, 14483456, 465...  16000   \n",
       "\n",
       "     Type                                               MFCC  \n",
       "373     0  [[38.812406955625654, -6.280405806858493, -13....  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_df.loc[song_df['Name'] == 'sing034_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the data repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_list = []\n",
    "\n",
    "for i in range(len(song_df.index)):\n",
    "    filename = \"spectrograms/\"+song_df.iloc[i].Name+\".png\"\n",
    "    temp_pic = cv2.imread(filename)\n",
    "    temp_pic = cv2.cvtColor(temp_pic, cv2.COLOR_RGB2GRAY)\n",
    "    temp_pic = temp_pic/255\n",
    "    spectro_list.append(copy.deepcopy(temp_pic[:, :47]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df['Spectrogram'] = pd.Series(spectro_list, index=song_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/scratch/s1769454/anaconda3/envs/dissertation/lib/python3.6/site-packages/pandas-0.23.1-py3.6-linux-x86_64.egg/pandas/core/generic.py:1993: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['Name', 'Data', 'MFCC', 'Spectrogram']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "song_df.to_hdf('song_df.h5', key='song_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating X and y for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "song_df = pd.read_hdf('song_df.h5', 'song_df')\n",
    "X = song_df.Spectrogram.values\n",
    "y = song_df.Type.values\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y = onehot_encoder.fit_transform(y.reshape(len(y), 1))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 47, 47)\n"
     ]
    }
   ],
   "source": [
    "X_new = np.zeros((1440, 47, 47))\n",
    "for i,d in enumerate(X):\n",
    "    X_new[i,:,:] = d[:, :]\n",
    "print(X_new.shape)\n",
    "X = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1101, 47, 47) (1101, 3)\n",
      "(195, 47, 47) (195, 3)\n",
      "(144, 47, 47) (144, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the generated datasets\n",
    "\n",
    "# Training set\n",
    "np.save(\"./numpy_ds/x_train_conv\", X_train)\n",
    "np.save(\"./numpy_ds/y_train_conv\", y_train)\n",
    "\n",
    "# Validation set\n",
    "np.save(\"./numpy_ds/x_val_conv\", X_val)\n",
    "np.save(\"./numpy_ds/y_val_conv\", y_val)\n",
    "\n",
    "# Test set\n",
    "np.save(\"./numpy_ds/x_test_conv\", X_test)\n",
    "np.save(\"./numpy_ds/y_test_conv\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading New dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"./numpy_ds/x_train_conv.npy\")\n",
    "X_val = np.load(\"./numpy_ds/x_val_conv.npy\")\n",
    "X_test = np.load(\"./numpy_ds/x_test_conv.npy\")\n",
    "\n",
    "y_train = np.load(\"./numpy_ds/y_train_conv.npy\")\n",
    "y_val = np.load(\"./numpy_ds/y_val_conv.npy\")\n",
    "y_test = np.load(\"./numpy_ds/y_test_conv.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectroCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LocatorCNN, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(1, 16, kernel_size=3, stride=1)\n",
    "        self.conv_layer2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, dilation=dilate)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv_layer3 = nn.Conv2d(32, 64, kernel_size=3, stride=1)\n",
    "        self.conv_layer4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, dilation=dilate)\n",
    "        #self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_layer5 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
    "        self.conv_layer6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, dilation=dilate)\n",
    "        #self.conv_layer7 = nn.Conv2d(128, 128, kernel_size=5, stride=1)\n",
    "        #self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "    \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.drop2 = nn.Dropout2d(p=0.1)\n",
    "        self.drop1 = nn.Dropout(p=0.05)\n",
    "        \n",
    "        self.activation_layer_2d = nn.Tanh()\n",
    "        self.activation_layer = nn.ELU()\n",
    "        \n",
    "        #self.linear_0 = nn.Linear(107648, 4096)\n",
    "        self.linear_1 = nn.Linear(115200, 2048) #with maxpooling\n",
    "        #self.linear_1 = nn.Linear(9750528, 2048)\n",
    "        self.linear_2 = nn.Linear(2048, 512)\n",
    "        self.linear_3 = nn.Linear(512, 128)\n",
    "        self.linear_4 = nn.Linear(128, 32)\n",
    "        self.linear_5 = nn.Linear(32, 8)\n",
    "        self.linear_6 = nn.Linear(8, 2)\n",
    "    \n",
    "    def forward(self, x, dim, channel):\n",
    "        x = x.view((1, 1, dim, -1))\n",
    "        channel = channel.view(-1)\n",
    "\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.activation_layer_2d(out)\n",
    "        #print(out.shape)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.batchnorm1(out)\n",
    "        #print(out.shape)\n",
    "        out = self.activation_layer_2d(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.drop2(out)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.activation_layer_2d(out)\n",
    "        #print(out.shape)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.activation_layer_2d(out)\n",
    "        #print(out.shape)\n",
    "        #out = self.batchnorm2(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.drop2(out)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        out = self.conv_layer5(out)\n",
    "        out = self.activation_layer_2d(out)\n",
    "        #out = self.batchnorm3(out)\n",
    "        #print(out.shape)\n",
    "        out = self.conv_layer6(out)\n",
    "        out = self.activation_layer_2d(out)\n",
    "        out = self.maxpool(out)\n",
    "        #out = self.drop2(out)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        out = out.view(-1)\n",
    "        \n",
    "        #out = self.linear_0(out)\n",
    "        #out = self.activation_layer(out)\n",
    "        #out = self.drop1(out)\n",
    "        out = self.linear_1(out)\n",
    "        out = self.activation_layer(out)\n",
    "        out = self.linear_2(out)\n",
    "        out = self.activation_layer(out)\n",
    "        out = self.drop1(out)\n",
    "        out = self.linear_3(out)\n",
    "        out = self.activation_layer(out)\n",
    "        out = self.linear_4(out)\n",
    "        out = self.activation_layer(out)\n",
    "        out = torch.cat((out, channel))\n",
    "        out = self.linear_5(out)\n",
    "        out = self.activation_layer(out)\n",
    "        out = self.linear_6(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
